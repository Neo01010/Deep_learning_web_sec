CNN出现之前，图像分类算法依赖于复杂的特征工程。
常用的特征提取方法包括SIFT（Scale-Invariant Feature Transform,尺度不变特征转换）
HOG(Histogram of Oriented Gradient, 方向梯度直方图）
LBP（Local Binary Pattern, 局部二值模式）等，常用的分类算法是SVM

基于CNN的图像分类算法：
直接把原始图像作为输入，使用深度学习算法直接进行图像分类，从而绕过复杂的特征工程。

1 局部连接
常见的深度学习算法都是全连接形式，全连接，就是第n-1层的任意一个节点都与第n层的所有节点有连接。
同时，临近输入层的隐藏层的任意节点与输入层的全部节点都有连接。参数过多

局部连接：隐藏层与输入层之间，隐藏层的一个节点只处理一部分输入层节点的数据，形成局部连接。


2 参数共享
本质上，隐藏层的一个节点与输入层的一个节点的连接，就对应着一个连接参数，大量的连接意味着大量的参数需要计算，
仅靠局部连接技术无法进一步减少计算量，于是提出了参数共享方法。

参数共享基于这样的假设：一部分图像的统计特性与完整图像的统计特性相同。
参数共享指每个隐藏层的节点都具有完全相同的参数。每一个过滤器在遍历整个图像的时候，过滤器的参数(即过滤器的参数的值)是固定不变的，
比如我有3个特征过滤器，每个过滤器都会扫描整个图像，在扫描的过程中，过滤器的参数值是固定不变的，即整个图像的所有元素都“共享”了相同的权值。
参数量只与卷积核的大小有关，即所谓的权值共享。


只有一个卷积核就只能提取一种卷积核滤波的结果，即只能提取一种图片特征，增加卷积核来提取多一些特征。
每个卷积核滤波得到的图像就是一类特征映射，即一个Feature Map

卷积的好处是，不管图片尺寸如何，我们需要训练的权值数量只与卷积核的大小和卷积核的数量有关，可以使用非常少的参数数量处理任意大小的图片。
每一个卷积层提取的特征，在后面的层中都会抽象组合成更高阶的特征。

注意：虽然训练的参数数量下降了，但是隐含节点的数目没有下降，隐含节点的数量只跟卷积的步长有关。如果步长为1，那么隐含节点的数量
和输入的图像像素数量一致，如果步长为5，那么每5*5的像素才需要一个隐含节点，隐含节点的数量就是输入像素数的1/25


3 池化层中的降采样
进一步降低了输出参数量，并赋予模型对轻度形变的容忍度，提高了模型的泛化能力。


局部连接和权值共享降低了参数量，使训练复杂度大大降低，并减轻了过拟合，同时权值共享还赋予卷积网络对平移的容忍性。

28*28*1  ->（卷积核3*3，数量32）->28*28*32 ->(池化2*2) ->14*14*32 ->
（卷积核3*3，数量64）->14*14*64 ->(池化2*2) ->7*7*64 ->（转换成一维向量）
->3136*1 -> 隐藏层128个节点的全连接层 -> 128*1 -> 隐藏层256个节点的全连接层
-> 256*1 -> 隐藏层10个节点的全连接 -> 1000*1


AlexNet 一共有8个层组成，其中5个卷基层，3个全连接层

Oxford's 17 Category Flower数据集：
不同种类鲜花的图像数据，包含17种不同种类的鲜花，每类80张该类鲜花的图片，这些鲜花种类在英国是常见的。
每张图片大小是227*227， 通道数为3，所以对应的张量大小为227*227*3.


227*227*3 ->(卷积核11*11 数量96, 步长为4)-> 55*55*96 -> (池化3*3，步长为2) -> 27*27*96
-> (卷积核5*5 数量256 same) -> 27*27*256 ->(池化3*3，步长为2) -> 13*13*256-> (卷积核3*3 数量384 same)
-> 13*13*384 ->(卷积核3*3 数量384 same) -> 13*13*384 ->(卷积核3*3 数量256 same)->13*13*256->
(池化3*3，步长为2) -> 6*6*256->  隐藏层9216个节点的全连接层 -> 9216*1 -> 隐藏层4096个节点的全连接层 ->
4096*1 -> 隐藏层4096个节点的全连接层-> 4096*1 ->softmax(1000) -> 1000*1


VGG16包含了16个隐藏层（13个卷积层和3个全连接层）
224*224*3 -> （卷积核3*3， 64） ->(卷积核3*3， 64)->224*224*64 -> (池化 2*2，s=2) ->112*112*64
-> （卷积核3*3， 128） ->(卷积核3*3， 128)->112*112*128 -> (池化 2*2，s=2) ->56*56*128->
（卷积核3*3， 256）->(卷积核3*3， 256)->(卷积核3*3， 256)->56*56*256 -> (池化 2*2，s=2) ->28*28*256->
（卷积核3*3， 512）->(卷积核3*3， 512)->(卷积核3*3， 512)->56*56*512 -> (池化 2*2，s=2) ->14*14*512->
（卷积核3*3， 512）->(卷积核3*3， 512)->(卷积核3*3， 512)->14*14*512 -> (池化 2*2，s=2) ->7*7*512->
 fc 4096 -> fc 4096->fc 4096




