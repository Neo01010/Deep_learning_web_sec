RNN等效于一连串共享系数的神经元串联在一起，也解释了RNN特别适合处理时序数据的原因。

LSTM的关键是神经细胞状态，水平线在图上方贯穿运行，细胞状态类似于传送带，状态通过水平线在细胞之间传递，从而保证长期记忆能够保存。

单向循环神经网络结构实现（LSTM）
在tensorflow中，LSTM被封装成一个组件，使用时只需指定节点数即可。


1 RNN在序列分类中的应用。
2 序列生成应用： char RNN模型：
        以字符为最小的单元，把每个字符当作一个输入，这样一个单词、一句话甚至一篇文章都可以看成由字符组成的一个序列，通常这样的字符集合会包括字母、数字和常用标点。
        RNN本质上只能理解数字序列，所以需要建立一个映射关系，把字符映射成数字，这种映射关系成为char-idx
3 序列标记应用：
    自然语言分析技术大致可以分为三个层面：词法分析、语法分析、语义分析。
    语义角色标注（Semantic Role Labelling， SRL）是实现浅层语义分析的一种方式。在一个句子中，谓词是对主语的陈述或说明，指出“做什么”、“是什么”、“怎么样”，
    代表了一个事件的核心。跟谓词搭配的名词称为论元。
    语义角色标注是以谓词为中心，不对句子所包含的语义信息进行深入分析，只分析句子中各成分与谓词之间的关系，是自然语言理解任务（如信息抽取、篇章分析、深度问答等）
    的一个重要步骤。
    在研究中，谓词一般是给定的，所做的就是找出给定谓词的各个论元与它们的语义角色。

    在SRL任务中，深层LSTM网络学习输入的特征表示，条件随机场（Conditional Random Field, CRF）在特征的基础上完成序列标注，处于整个网络的末端。
    CRF是一种概率化结构模型，可以看作是一个概率无向图模型，节点表示随机变量，边表示随机变量之间的概率依赖关系。


4 序列翻译应用：
    序列翻译又称Seq2Seq(Seqence to Sequence, 序列到序列)，本质上是LSTM将输入序列转化成另一个序列，如机器翻译。
    机器翻译实现源语言到目标语言的转换过程。
    统计机器翻译（Statistical Machine Transaction，SMT）：转化规则是由机器从大规模语料中学习的到的。

    将深度学习应用于机器翻译任务的方法大致分为两类：
    仍使用SMT的框架，只是利用神经网络来改进其中的关键模块，如语言模型、调序模型等
    直接用神经网络将源语言映射到目标语言，即端到端的神经网络机器翻译（End-to-End Neural Machine Translation, End-to-End NMT）,简称NMT模型
